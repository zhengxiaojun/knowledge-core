# AI 测试用例自动生成系统  
## 技术详细设计文档

**Version:** 1.0  
**文档名称:** AI 测试用例自动生成系统 - 技术详细设计文档  
**创建日期:** 2026-01-28  
**状态:** 待评审  

---

## 1. 总体架构设计

### 1.1 设计原则

- 测试知识优先，而非文档优先  
  系统以测试知识单元为核心，而不是原始文档  
- 语义驱动，而非 ID 驱动  
  使用语义相似度而不是简单的 ID 匹配  
- 分阶段推理生成，而非一次性生成  
  采用「意图 → 测试点 → 测试用例」的三阶段生成策略  
- 可解释、可回溯、可持续学习  
  确保系统的可维护性和长期演进能力  

---

### 1.2 技术栈选型

| 层级 | 技术选型 | 说明 |
|----|----|----|
| 后端语言 | Python 3.9+ | 生态成熟，适配 LLM 与数据处理 |
| Web 框架 | FastAPI | 高性能，天然支持异步与 AI 服务 |
| 任务调度 | Celery / RQ | 支持向量化、生成等异步任务 |
| 向量数据库 | Milvus | 大规模语义检索 |
| 图数据库 | Neo4j 4.x / 5.x | 测试事实与关系建模 |
| 关系数据库 | MySQL | 需求、任务、生成结果 |
| 大语言模型 | GPT-4 / Claude | 测试意图、测试点、用例生成 |
| Embedding | text-embedding-3 / BGE | 测试知识向量化 |

---

### 1.3 架构分层

系统采用分层架构，自下而上包括：

- **数据存储层**：关系数据库、向量数据库、图数据库  
- **数据处理层**：文档解析、数据接入、知识抽取  
- **AI 能力层**：向量检索、图谱查询、LLM 生成  
- **业务服务层**：需求管理、用例生成、质量管理  
- **API 网关层**：统一入口、鉴权、限流、路由  

---

### 1.4 核心模块

- 文档解析与需求还原模块（Step 0）  
- 历史数据接入与标准化模块（Step 1）  
- 测试知识抽取模块（Step 2）  
- 向量化与入库模块（Step 3）  
- 图谱构建模块（Step 4）  
- 子图检索与上下文构建模块（Step 5）  
- LLM 分阶段生成引擎（Step 6）  

---

## 2. 核心概念定义

### 2.1 测试知识单元（Test Knowledge Unit）

测试知识单元是系统的核心抽象概念，是可作为测试分析入口的最小语义单元，包括：

- **测试点（TestPoint）**：如「支付超时处理」「订单状态校验」  
- **测试场景（Scenario）**：如「订单状态异常流转」「并发支付场景」  
- **风险点 / 缺陷抽象（Risk）**：如「重复回调导致重复扣款」  

**特点：**

- 语义稳定：不包含易变的实现细节  
- 可复用：可在不同需求中反复使用  
- 可关联：能够关联历史用例和缺陷  

---

### 2.2 数据传输对象（DTO）

系统定义统一的中间数据模型，所有下游模块只认该结构：

- Requirement DTO：标准化需求对象  
- TestCase DTO：标准化测试用例对象  
- Defect DTO：标准化缺陷对象  
- TestKnowledgeUnit DTO：测试知识单元对象  

---

## 3. 数据流设计

### 3.1 全链路数据流

```text
历史系统（需求 / 用例 / 缺陷）
        ↓
Step 1：数据接入 & 统一模型（Data Normalize）
        ↓                         ↓
Step 2：测试知识抽取        Step 4：事实节点入图
        ↓
Step 3：向量化入库
        ↓
Step 5：子图检索（向量库 + 图数据库）
        ↓
Step 6：LLM 分阶段生成
        ↓
测试用例输出 & 知识回流
```

---

### 3.2 关键约束

* 任意模块不得直接读取原始数据，必须通过 Step 1 的统一模型
* Step 1 是系统唯一的数据入口
* 向量检索结果不可直接作为生成输入，必须经过图谱扩展
* 用户原始需求全文仅保存在 `requirement_raw` 表中，不参与向量化

---

## 4. 模块详细设计

### 4.1 Step 0：文档解析与需求还原

#### 4.1.1 设计目标

将非结构化文档还原为 LLM 可稳定消费的需求表达。

#### 4.1.2 技术选型

* PDF：pdfplumber / PyMuPDF
* Word：python-docx
* Excel：pandas / openpyxl
* OCR：PaddleOCR / Tesseract

#### 4.1.3 处理流程

1. 文档切块（Chunking）：按标题、表格、语义段落拆分
2. LLM 需求还原：提取真实需求描述
3. 结构化输出：生成 Requirement Raw DTO

#### 4.1.4 输出结构

Requirement Raw DTO：

* raw_req_id
* title
* full_content
* source_type（text / pdf / docx）
* origin_file

---

### 4.2 Step 1：历史数据接入与标准化

#### 4.2.1 设计目标

统一异构测试资产，形成标准中间模型。

#### 4.2.2 数据来源

* Jira / 禅道 REST API
* MySQL / PostgreSQL
* Markdown / Excel / CSV

#### 4.2.3 统一 DTO 结构

| DTO 类型          | 核心字段                                                          |
| --------------- | ------------------------------------------------------------- |
| Requirement DTO | req_id, title, description, business_domain, priority, source |
| TestCase DTO    | case_id, related_req_id, summary, steps, expected             |
| Defect DTO      | defect_id, related_req_id, phenomenon, root_cause             |

---

### 4.3 Step 2：测试知识抽取

#### 4.3.1 设计原则

* 不直接生成测试用例
* 先抽象测试思维，再生成用例
* 剥离强实现绑定的细节

#### 4.3.2 抽取方式

* LLM 抽象测试点 / 场景 / 风险
* 规则兜底：去重、合并、长度控制

#### 4.3.3 Prompt 模板示例

```text
【角色】
你是一名资深测试架构师，擅长从需求与缺陷中抽象稳定测试知识。
【任务】
1. 抽象稳定、可复用的测试点 / 场景 / 风险
2. 不包含 UI、接口字段、实现细节
3. 每条必须可长期复用
【输出】
JSON 数组：type, content, confidence
```

---

### 4.4 Step 3：向量化与入库

#### 4.4.1 设计原则

向量库只用于「找入口」，不用于承载完整上下文。

#### 4.4.2 向量 Schema

* id
* embedding
* content
* type（TestPoint / Scenario / Risk）
* graph_id
* source
* confidence

#### 4.4.3 入库策略

* 历史批量导入
* 实时增量导入
* Upsert 更新机制

---

### 4.5 Step 4：图谱构建

#### 4.5.1 设计原则

Neo4j 只负责组织测试事实，不参与相似度搜索。

#### 4.5.2 节点类型

* Requirement
* TestPoint
* TestCase
* Defect

#### 4.5.3 关系设计

* `(:Requirement)-[:DERIVE]->(:TestPoint)`
* `(:TestPoint)-[:COVERED_BY]->(:TestCase)`
* `(:TestPoint)-[:TRIGGERED]->(:Defect)`
* `(:TestCase)-[:RELATED_TO]->(:Defect)`

---

### 4.6 Step 5：子图检索与上下文构建

#### 4.6.1 检索流程

1. 向量检索 Top-K 测试知识入口
2. Neo4j 子图扩展
3. 上下文结构化输出

#### 4.6.2 子图扩展策略

* 入口节点：测试知识单元
* 扩展深度：2–3 跳
* 严格限制节点数量

#### 4.6.3 上下文裁剪规则

* 用例：前置条件 / 核心步骤 / 断言
* 缺陷：问题现象 + 根因
* 移除冗余和无关字段

---

### 4.7 Step 6：LLM 分阶段生成

#### 4.7.1 生成策略

采用 Planner → Executor 模式：

1. 测试意图拆解
2. 测试点生成
3. 测试用例生成

#### 4.7.2 Prompt 失败处理

失败输出协议：

```json
{
  "status": "FAILED",
  "reason": "insufficient_context | conflict_information | unsupported_requirement"
}
```

处理规则：

* FAILED 状态禁止进入下一阶段
* 回退人工补充或重新触发上游 Step

---

## 5. 关键设计决策

### 5.1 不向量化需求全文的原因

* 向量检索负责找参考
* LLM 负责理解全文
* 向量库存储抽象测试知识
* 生成时始终使用完整需求正文

---

### 5.2 AI Gateway 的必要性

* 只负责：Prompt 管理、模型路由、成本治理
* 禁止：直接访问业务数据库
* 目标：保持业务逻辑可控、可调试

---

### 5.3 Step 职责边界

* Step 1：禁止生成测试点、用例
* Step 2：禁止相似度搜索
* Step 3：禁止承载上下文

---

### 5.4 测试知识治理

* Review / Merge 机制
* 周期性相似测试点聚合
* 置信度衰减与提升规则

---

## 6. 性能优化设计

### 6.1 向量检索优化

* HNSW / IVF_FLAT 索引
* Top-K 控制（10–20）
* 高频结果缓存

### 6.2 图谱查询优化

* 限制扩展深度
* 控制返回节点数量
* 核心索引设计

### 6.3 LLM 调用优化

* 测试点并行生成
* Prompt 缓存
* 异步任务队列

---

## 7. 安全性设计

### 7.1 身份认证

* JWT
* API Key
* OAuth 2.0

### 7.2 数据安全

* 敏感信息加密
* 权限控制
* 审计日志

### 7.3 接口安全

* API 限流
* 输入校验
* HTTPS

---

## 8. 可观测性设计

### 8.1 日志系统

* ELK / Loki
* 结构化日志
* Prompt 与结果关联

### 8.2 指标监控

* Prometheus + Grafana
* 生成耗时、命中率、Token 消耗
* 告警规则

### 8.3 链路追踪

* OpenTelemetry
* 全流程可视化
* 性能瓶颈分析
